---
title: "2. R Programming: Week 4 Notes"
output: html_notebook
---

# Simulation & Profiling
This week is about how to simulate data in R. We also talk about the profiler, which lets you collect detailed information about how your R functions are running and to identify the bottlenecks that can speed things up.

## The `str()` function: the most useful function in R
Sort of like `summary()`, good for compact display. Roughly 1 line per object. Answers the question, "What's in this object?"

I won't go into detail about it right now, just use it. `str()` everything. Every time you need to learn about something in R, start with `str()`. You can't memorize every possible output of this incredibly useful function, so just use it all the damn time and you'll get the hang of it.

## Simulation

### Generating random numbers
Generating random numbers according to some probability distribution. The common random number functions in R are:

* `rnorm`: generate random normal variates with a given mean and sd
* `dnorm`: evaluate the normal probability density (with a given mean/sd) at a point (or vector of points)
* `pnorm`: evaluate the cumulative probability distribution function for a normal distribution
* `rpois`: generate random Poisson variates with a given rate

In general, probability distribution functions will have 4 associated functions, each starting with:

* `d` for density
* `r` for random number generation
* `p` for cumulative distribution
* `q` for quantile function

The crash course in statistics is several classes down the road in this specialization...

When working with random numbers, remember to `set.seed(n)`. This makes random number generation reproducible.

### Simulating a linear model
The last section is great for generating data from a theoretical distribution, but what if you need to generate data according to a linear model? Well here it is.

Suppose we want to simulate data from this model: $y = \beta_0 + \beta_1 X + \epsilon$ where $\epsilon$ is random noise according to $\mathcal{N}(0, 2)$. Assume $X$ is $\mathcal{N}(0, 1)$, $\beta_0 = 0.5$, and $\beta_1 = 2$.

Here's how we would generate data from this model:

```{r}
set.seed(20)
x <- rnorm(100)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2*x + e
summary(y)
plot(x, y)
```

Now let's make $X$ a binary random variable:

```{r}
set.seed(10)
x <- rbinom(100, 1, 0.5)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2*x + e
summary(y)
plot(x, y)
```

And now for Poisson.

```{r}
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3*x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x, y)
```

### Random sampling
The `sample` function draws randomly from a specified set of objects.

```{r}
set.seed(1)
sample(1:10, 4)     # default is replace = FALSE
sample(1:10, 4)
sample(letters, 5)
sample(1:10)        # permutation
sample(1:10)
sample(1:10, replace = TRUE)
```

## R profiler
All about optimizing your code.

Don't bother optimizing code first. Get it to work, focus on the goal, then revise as necessary. Also, know when this isn't important.

### `system.time()`
Returns the amount of time taken to evaluate the expression passed to it. Tells you 2 times (in seconds): user time (time charged to the CPU) and elapsed time (wall clock time). Returns an object of class `proc_time`.

User time and elapsed time will usually be pretty close. Elapsed time bay be >> user time if the CPU has a bunch fo stuff to do, and doesn't get around to your job immediately. User time may be >> elapsed time if you have lots of processors to share the load. (Note that R doesn't do parallel by default, though.)

You can wrap longer expressions in {} and put the whole thing inside `system.time()`. For example:

```{r}
system.time({
     n <- 1000
     r <- numeric(n)
     for (i in 1:n) {
          x <- rnorm(n)
          r[i] <- mean(x)
     }
})
```

### R profiler
`Rprof()` starts the profiler. R must be compiled with support for this, but that's almost always the case. The native output is worthless, so you can use the `summaryRprof()` function to make sense of it. Finally, **DO NOT** use `system.time()` and `Rprof()` together or "you will be sad."

`Rprof` basically keeps track of the function call stack at regularly sampled intervals (0.02 seconds). This basically turns into timestamps associated with functions that are in-process.

`summaryRprof()` tabulates the profiler's output to tell you how much time is spent in what function. You can normalize this `by.total` or `by.self`.

* `by.total` divides the time spent in each function by the total run time. Because functions call functions, they can become nested. This means you spent 100% of your time in the top-level function `by.total`, and that's kind of useless to know
* `by.self` subtracts time spent in nested functions in the call stack, then divides the time spent in the function. This tells you the time spent by function, but only truly "in" that function, not in the function but on behalf of another function.
